{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ual\\.conda\\envs\\felix\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import pandas as pd\n",
    "import seq_generator\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_datasets as tfds\n",
    "import json\n",
    "import os\n",
    "\n",
    "pars = json.load(open(\"tuner_run/best_hps.json\"))\n",
    "\n",
    "train_ds , val_ds = seq_generator.get_train_and_val(batch_size=128)\n",
    "train_ds = train_ds.map(lambda x,y: (x,tf.one_hot(y,2)))\n",
    "val_ds = val_ds.map(lambda x,y: (x,tf.one_hot(y,2)))\n",
    "\n",
    "\n",
    "def build_cnn():\n",
    "\n",
    "    inputs = tf.keras.Input([260,260,3])\n",
    "\n",
    "    img_augmentation = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.RandomRotation(factor=0.15),\n",
    "            tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "            tf.keras.layers.RandomContrast(factor=0.1),\n",
    "        ],\n",
    "        name=\"img_augmentation\",\n",
    "    )\n",
    "\n",
    "    x = tf.keras.layers.Resizing(224,224) (inputs)\n",
    "\n",
    "    x = img_augmentation(x)\n",
    "\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                input_tensor= x)\n",
    "\n",
    "    base.trainable = False\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(base.output)\n",
    "\n",
    "    return tf.keras.Model(inputs,x)\n",
    "\n",
    "def build_model(hps,cnn):\n",
    "\n",
    "\n",
    "    inputs = tf.keras.Input([5,260,260,3])\n",
    "    x = layers.TimeDistributed(cnn)(inputs)\n",
    "\n",
    "    drop1 = hps[\"drop1\"]\n",
    "\n",
    "    x = layers.TimeDistributed( layers.Dropout(drop1), name = \"drop1\") (x)\n",
    "\n",
    "    hidden_units =  hps[\"hidden_units\"]\n",
    "\n",
    "    if hps[\"rnn\"] == \"lstm\":\n",
    "        x = layers.LSTM(hidden_units, name = \"lstm\")(x)\n",
    "    else:\n",
    "        x = layers.GRU(hidden_units, name = \"gru\") (x)\n",
    "\n",
    "    drop2 = hps[\"drop2\"]\n",
    "    x = layers.Dropout(drop2,name =\"drop2\")(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"pred\",kernel_regularizer=tf.keras.regularizers.L2())(x)\n",
    "\n",
    "    learning_rate = hps[\"lr\"]\n",
    "\n",
    "    model = tf.keras.Model(inputs,outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def warm_model(cnn):\n",
    "    cnn.trainable = True\n",
    "    for layer in cnn.layers:\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "\n",
    "    for layer in cnn.layers[:-20]:\n",
    "\n",
    "            layer.trainable = False\n",
    "\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def get_callbacks(name):\n",
    "    log_dir = f\"tuner_run/ensemble/lots/{name}/\"\n",
    "    save_dir = f\"tuner_run/ensemble/weights/{name}_warm/\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    os.makedirs(log_dir,exist_ok=True)\n",
    "    callbacks = []\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    filepath=save_dir + \"cp.cpkt\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True))\n",
    "\n",
    "    callbacks.append(tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto'))\n",
    "\n",
    "    callbacks.append( tf.keras.callbacks.TensorBoard(log_dir=log_dir))\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def run(name):\n",
    "\n",
    "    cnn = build_cnn()\n",
    "    model = build_model(pars,cnn)\n",
    "    print(\"jo\")\n",
    "    model.fit(train_ds, epochs=1, validation_data=val_ds)\n",
    "    print(\"was\")\n",
    "    save_dir = f\"tuner_run/ensemble/weights/{name}_cold/\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    model.save_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "\n",
    "    cnn = warm_model(cnn)\n",
    "    model = build_model(pars,cnn)\n",
    "    model.load_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "    callbacks = get_callbacks(name)\n",
    "    model.fit(train_ds, epochs=1, validation_data=val_ds,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jo\n",
      "283/283 [==============================] - 126s 403ms/step - loss: 0.1439 - accuracy: 0.9579 - val_loss: 0.4479 - val_accuracy: 0.8277\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9832\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92241, saving model to tuner_run/ensemble/weights/b0_ensemple_0_warm\\cp.cpkt\n",
      "283/283 [==============================] - 133s 438ms/step - loss: 0.0677 - accuracy: 0.9832 - val_loss: 0.2242 - val_accuracy: 0.9224\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9951\n",
      "Epoch 2: val_accuracy did not improve from 0.92241\n",
      "283/283 [==============================] - 121s 428ms/step - loss: 0.0275 - accuracy: 0.9951 - val_loss: 0.2789 - val_accuracy: 0.9000\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9966\n",
      "Epoch 3: val_accuracy did not improve from 0.92241\n",
      "283/283 [==============================] - 121s 427ms/step - loss: 0.0200 - accuracy: 0.9966 - val_loss: 0.2395 - val_accuracy: 0.9073\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9977\n",
      "Epoch 4: val_accuracy did not improve from 0.92241\n",
      "283/283 [==============================] - 122s 429ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.3337 - val_accuracy: 0.8955\n",
      "Epoch 4: early stopping\n",
      "0 [0.9224099516868591, 0.8999555110931396, 0.9072921276092529, 0.8955091238021851]\n",
      "jo\n",
      "283/283 [==============================] - 121s 407ms/step - loss: 0.1429 - accuracy: 0.9589 - val_loss: 0.5995 - val_accuracy: 0.7837\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9819\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91418, saving model to tuner_run/ensemble/weights/b0_ensemple_1_warm\\cp.cpkt\n",
      "283/283 [==============================] - 132s 439ms/step - loss: 0.0717 - accuracy: 0.9819 - val_loss: 0.2522 - val_accuracy: 0.9142\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9953\n",
      "Epoch 2: val_accuracy did not improve from 0.91418\n",
      "283/283 [==============================] - 121s 428ms/step - loss: 0.0280 - accuracy: 0.9953 - val_loss: 0.3759 - val_accuracy: 0.8744\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9961\n",
      "Epoch 3: val_accuracy improved from 0.91418 to 0.92597, saving model to tuner_run/ensemble/weights/b0_ensemple_1_warm\\cp.cpkt\n",
      "283/283 [==============================] - 122s 429ms/step - loss: 0.0211 - accuracy: 0.9961 - val_loss: 0.2372 - val_accuracy: 0.9260\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9976\n",
      "Epoch 4: val_accuracy did not improve from 0.92597\n",
      "283/283 [==============================] - 120s 424ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.4320 - val_accuracy: 0.8811\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9977\n",
      "Epoch 5: val_accuracy improved from 0.92597 to 0.93819, saving model to tuner_run/ensemble/weights/b0_ensemple_1_warm\\cp.cpkt\n",
      "283/283 [==============================] - 121s 426ms/step - loss: 0.0154 - accuracy: 0.9977 - val_loss: 0.1854 - val_accuracy: 0.9382\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9977\n",
      "Epoch 6: val_accuracy improved from 0.93819 to 0.94175, saving model to tuner_run/ensemble/weights/b0_ensemple_1_warm\\cp.cpkt\n",
      "283/283 [==============================] - 121s 425ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1795 - val_accuracy: 0.9418\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9981\n",
      "Epoch 7: val_accuracy did not improve from 0.94175\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.3554 - val_accuracy: 0.9024\n",
      "1 [0.9141840934753418, 0.8743886351585388, 0.9259670972824097, 0.8810582756996155, 0.938194751739502, 0.9417518973350525, 0.9024010896682739]\n",
      "jo\n",
      "283/283 [==============================] - 120s 400ms/step - loss: 0.1448 - accuracy: 0.9587 - val_loss: 0.3972 - val_accuracy: 0.8368\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9827\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91641, saving model to tuner_run/ensemble/weights/b0_ensemple_2_warm\\cp.cpkt\n",
      "283/283 [==============================] - 131s 437ms/step - loss: 0.0676 - accuracy: 0.9827 - val_loss: 0.2410 - val_accuracy: 0.9164\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9949\n",
      "Epoch 2: val_accuracy did not improve from 0.91641\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0268 - accuracy: 0.9949 - val_loss: 0.3143 - val_accuracy: 0.9004\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9965\n",
      "Epoch 3: val_accuracy improved from 0.91641 to 0.94131, saving model to tuner_run/ensemble/weights/b0_ensemple_2_warm\\cp.cpkt\n",
      "283/283 [==============================] - 121s 425ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.1782 - val_accuracy: 0.9413\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy improved from 0.94131 to 0.94220, saving model to tuner_run/ensemble/weights/b0_ensemple_2_warm\\cp.cpkt\n",
      "283/283 [==============================] - 121s 426ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.1728 - val_accuracy: 0.9422\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9978\n",
      "Epoch 5: val_accuracy did not improve from 0.94220\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.2229 - val_accuracy: 0.9266\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9983\n",
      "Epoch 6: val_accuracy did not improve from 0.94220\n",
      "283/283 [==============================] - 114s 402ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.2140 - val_accuracy: 0.9337\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9982\n",
      "Epoch 7: val_accuracy did not improve from 0.94220\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.2941 - val_accuracy: 0.9151\n",
      "Epoch 7: early stopping\n",
      "2 [0.9164072871208191, 0.9004001617431641, 0.9413072466850281, 0.9421965479850769, 0.9266340732574463, 0.9337483048439026, 0.9150733947753906]\n",
      "jo\n",
      "283/283 [==============================] - 105s 352ms/step - loss: 0.1405 - accuracy: 0.9582 - val_loss: 0.2849 - val_accuracy: 0.8911\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9817\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89395, saving model to tuner_run/ensemble/weights/b0_ensemple_3_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 385ms/step - loss: 0.0736 - accuracy: 0.9817 - val_loss: 0.3165 - val_accuracy: 0.8940\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9949\n",
      "Epoch 2: val_accuracy improved from 0.89395 to 0.91841, saving model to tuner_run/ensemble/weights/b0_ensemple_3_warm\\cp.cpkt\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0289 - accuracy: 0.9949 - val_loss: 0.2605 - val_accuracy: 0.9184\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9969\n",
      "Epoch 3: val_accuracy did not improve from 0.91841\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.2394 - val_accuracy: 0.9175\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.91841\n",
      "283/283 [==============================] - 108s 383ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.3512 - val_accuracy: 0.8888\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9980\n",
      "Epoch 5: val_accuracy improved from 0.91841 to 0.93130, saving model to tuner_run/ensemble/weights/b0_ensemple_3_warm\\cp.cpkt\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.2250 - val_accuracy: 0.9313\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9982\n",
      "Epoch 6: val_accuracy did not improve from 0.93130\n",
      "283/283 [==============================] - 120s 424ms/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.2772 - val_accuracy: 0.9162\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9986\n",
      "Epoch 7: val_accuracy improved from 0.93130 to 0.93575, saving model to tuner_run/ensemble/weights/b0_ensemple_3_warm\\cp.cpkt\n",
      "283/283 [==============================] - 120s 424ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 0.2260 - val_accuracy: 0.9357\n",
      "3 [0.8939528465270996, 0.9184081554412842, 0.9175189137458801, 0.8888394832611084, 0.9313027858734131, 0.9161849617958069, 0.9357492327690125]\n",
      "jo\n",
      "283/283 [==============================] - 120s 400ms/step - loss: 0.1377 - accuracy: 0.9617 - val_loss: 0.3107 - val_accuracy: 0.8779\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9808\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87839, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 130s 434ms/step - loss: 0.0746 - accuracy: 0.9808 - val_loss: 0.3424 - val_accuracy: 0.8784\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9948\n",
      "Epoch 2: val_accuracy improved from 0.87839 to 0.91908, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0295 - accuracy: 0.9948 - val_loss: 0.2348 - val_accuracy: 0.9191\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9963\n",
      "Epoch 3: val_accuracy improved from 0.91908 to 0.92197, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 120s 424ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 0.2133 - val_accuracy: 0.9220\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9977\n",
      "Epoch 4: val_accuracy improved from 0.92197 to 0.92441, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 111s 393ms/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 0.2306 - val_accuracy: 0.9244\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 5: val_accuracy did not improve from 0.92441\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.2368 - val_accuracy: 0.9189\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9974\n",
      "Epoch 6: val_accuracy improved from 0.92441 to 0.93842, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.2079 - val_accuracy: 0.9384\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9980\n",
      "Epoch 7: val_accuracy improved from 0.93842 to 0.94887, saving model to tuner_run/ensemble/weights/b0_ensemple_4_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.1523 - val_accuracy: 0.9489\n",
      "4 [0.878390371799469, 0.9190751314163208, 0.9219653010368347, 0.9244108200073242, 0.9188528060913086, 0.9384170770645142, 0.9488661885261536]\n",
      "jo\n",
      "283/283 [==============================] - 106s 353ms/step - loss: 0.1439 - accuracy: 0.9598 - val_loss: 0.4891 - val_accuracy: 0.8217\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9831\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88084, saving model to tuner_run/ensemble/weights/b0_ensemple_5_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 383ms/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 0.3488 - val_accuracy: 0.8808\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9952\n",
      "Epoch 2: val_accuracy improved from 0.88084 to 0.92463, saving model to tuner_run/ensemble/weights/b0_ensemple_5_warm\\cp.cpkt\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 0.2276 - val_accuracy: 0.9246\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9963\n",
      "Epoch 3: val_accuracy did not improve from 0.92463\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.2733 - val_accuracy: 0.8997\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9970\n",
      "Epoch 4: val_accuracy did not improve from 0.92463\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0166 - accuracy: 0.9970 - val_loss: 0.2473 - val_accuracy: 0.9200\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9974\n",
      "Epoch 5: val_accuracy improved from 0.92463 to 0.93642, saving model to tuner_run/ensemble/weights/b0_ensemple_5_warm\\cp.cpkt\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.1759 - val_accuracy: 0.9364\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 6: val_accuracy did not improve from 0.93642\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.3430 - val_accuracy: 0.9035\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9985\n",
      "Epoch 7: val_accuracy did not improve from 0.93642\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.3081 - val_accuracy: 0.9122\n",
      "5 [0.8808359503746033, 0.9246331453323364, 0.8997331857681274, 0.9199644327163696, 0.9364162087440491, 0.9035126566886902, 0.9121831655502319]\n",
      "jo\n",
      "283/283 [==============================] - 105s 352ms/step - loss: 0.1438 - accuracy: 0.9572 - val_loss: 0.4746 - val_accuracy: 0.8277\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9801\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92152, saving model to tuner_run/ensemble/weights/b0_ensemple_6_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 384ms/step - loss: 0.0761 - accuracy: 0.9801 - val_loss: 0.2369 - val_accuracy: 0.9215\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9947\n",
      "Epoch 2: val_accuracy did not improve from 0.92152\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 0.2699 - val_accuracy: 0.9020\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9966\n",
      "Epoch 3: val_accuracy did not improve from 0.92152\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0202 - accuracy: 0.9966 - val_loss: 0.3463 - val_accuracy: 0.8964\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9976\n",
      "Epoch 4: val_accuracy did not improve from 0.92152\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.3622 - val_accuracy: 0.8904\n",
      "Epoch 4: early stopping\n",
      "6 [0.9215206503868103, 0.9019564390182495, 0.8963984251022339, 0.8903957605361938]\n",
      "jo\n",
      "283/283 [==============================] - 106s 352ms/step - loss: 0.1434 - accuracy: 0.9579 - val_loss: 0.3247 - val_accuracy: 0.8651\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9835\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92374, saving model to tuner_run/ensemble/weights/b0_ensemple_7_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 384ms/step - loss: 0.0657 - accuracy: 0.9835 - val_loss: 0.2303 - val_accuracy: 0.9237\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9948\n",
      "Epoch 2: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0276 - accuracy: 0.9948 - val_loss: 0.4649 - val_accuracy: 0.8482\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9970\n",
      "Epoch 3: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.2957 - val_accuracy: 0.9066\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9969\n",
      "Epoch 4: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.2638 - val_accuracy: 0.9157\n",
      "Epoch 4: early stopping\n",
      "7 [0.9237439036369324, 0.8481547236442566, 0.9066251516342163, 0.9157403111457825]\n",
      "jo\n",
      "283/283 [==============================] - 106s 355ms/step - loss: 0.1416 - accuracy: 0.9587 - val_loss: 0.3375 - val_accuracy: 0.8684\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9819\n",
      "Epoch 1: val_accuracy improved from -inf to 0.90062, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 383ms/step - loss: 0.0704 - accuracy: 0.9819 - val_loss: 0.2930 - val_accuracy: 0.9006\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9951\n",
      "Epoch 2: val_accuracy improved from 0.90062 to 0.90173, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0281 - accuracy: 0.9951 - val_loss: 0.2916 - val_accuracy: 0.9017\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 3: val_accuracy did not improve from 0.90173\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0202 - accuracy: 0.9967 - val_loss: 0.3243 - val_accuracy: 0.8995\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9969\n",
      "Epoch 4: val_accuracy improved from 0.90173 to 0.90952, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 378ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.2492 - val_accuracy: 0.9095\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9975\n",
      "Epoch 5: val_accuracy improved from 0.90952 to 0.91374, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 379ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.2710 - val_accuracy: 0.9137\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9979\n",
      "Epoch 6: val_accuracy improved from 0.91374 to 0.93041, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.1983 - val_accuracy: 0.9304\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9984\n",
      "Epoch 7: val_accuracy improved from 0.93041 to 0.93108, saving model to tuner_run/ensemble/weights/b0_ensemple_8_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 0.2165 - val_accuracy: 0.9311\n",
      "8 [0.9006224870681763, 0.9017341136932373, 0.89951092004776, 0.9095153212547302, 0.9137394428253174, 0.930413544178009, 0.9310804605484009]\n",
      "jo\n",
      "283/283 [==============================] - 105s 354ms/step - loss: 0.1440 - accuracy: 0.9577 - val_loss: 0.3370 - val_accuracy: 0.8666\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9853\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88884, saving model to tuner_run/ensemble/weights/b0_ensemple_9_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 384ms/step - loss: 0.0622 - accuracy: 0.9853 - val_loss: 0.3088 - val_accuracy: 0.8888\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9948\n",
      "Epoch 2: val_accuracy improved from 0.88884 to 0.90863, saving model to tuner_run/ensemble/weights/b0_ensemple_9_warm\\cp.cpkt\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 0.2633 - val_accuracy: 0.9086\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9967\n",
      "Epoch 3: val_accuracy did not improve from 0.90863\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.2371 - val_accuracy: 0.9086\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.90863\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 0.4317 - val_accuracy: 0.8777\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9978\n",
      "Epoch 5: val_accuracy improved from 0.90863 to 0.92285, saving model to tuner_run/ensemble/weights/b0_ensemple_9_warm\\cp.cpkt\n",
      "283/283 [==============================] - 110s 389ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.2420 - val_accuracy: 0.9229\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9977\n",
      "Epoch 6: val_accuracy did not improve from 0.92285\n",
      "283/283 [==============================] - 122s 430ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.3181 - val_accuracy: 0.9102\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9987\n",
      "Epoch 7: val_accuracy did not improve from 0.92285\n",
      "283/283 [==============================] - 122s 429ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.2992 - val_accuracy: 0.9160\n",
      "9 [0.8888394832611084, 0.9086260795593262, 0.9086260795593262, 0.8777234554290771, 0.9228546023368835, 0.9101822972297668, 0.9159626364707947]\n"
     ]
    }
   ],
   "source": [
    "perfomances = {}\n",
    "for i in range(10):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    name = f\"b0_ensemple_{i}\"\n",
    "    cnn = build_cnn()\n",
    "\n",
    "    model = build_model(pars,cnn)\n",
    "\n",
    "    model\n",
    "    print(\"jo\")\n",
    "    model.fit(train_ds, epochs=1, validation_data=val_ds)\n",
    "\n",
    "    print(\"was\")\n",
    "    save_dir = f\"tuner_run/ensemble/weights/{name}_cold/\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    model.save_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "\n",
    "    cnn = warm_model(cnn)\n",
    "    model = build_model(pars,cnn)\n",
    "    model.load_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "    callbacks = get_callbacks(name)\n",
    "    hist = model.fit(train_ds, epochs=7, validation_data=val_ds,callbacks=callbacks)\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    max_acc = max(val_acc)\n",
    "\n",
    "    perfomances[i] = val_acc\n",
    "\n",
    "    print(i,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jo\n",
      "283/283 [==============================] - 120s 401ms/step - loss: 0.1441 - accuracy: 0.9585 - val_loss: 0.2847 - val_accuracy: 0.8962\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9763\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89551, saving model to tuner_run/ensemble/weights/b0_ensemple_10_warm\\cp.cpkt\n",
      "283/283 [==============================] - 132s 435ms/step - loss: 0.0874 - accuracy: 0.9763 - val_loss: 0.2845 - val_accuracy: 0.8955\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9949\n",
      "Epoch 2: val_accuracy improved from 0.89551 to 0.93464, saving model to tuner_run/ensemble/weights/b0_ensemple_10_warm\\cp.cpkt\n",
      "283/283 [==============================] - 121s 425ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.1921 - val_accuracy: 0.9346\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9956\n",
      "Epoch 3: val_accuracy did not improve from 0.93464\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 0.2430 - val_accuracy: 0.9133\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9974\n",
      "Epoch 4: val_accuracy did not improve from 0.93464\n",
      "283/283 [==============================] - 120s 425ms/step - loss: 0.0175 - accuracy: 0.9974 - val_loss: 0.1932 - val_accuracy: 0.9311\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9978\n",
      "Epoch 5: val_accuracy did not improve from 0.93464\n",
      "283/283 [==============================] - 114s 401ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.3217 - val_accuracy: 0.9011\n",
      "Epoch 5: early stopping\n",
      "10 [0.8955091238021851, 0.9346376061439514, 0.913294792175293, 0.9310804605484009, 0.9010671377182007]\n",
      "jo\n",
      "283/283 [==============================] - 105s 353ms/step - loss: 0.1406 - accuracy: 0.9605 - val_loss: 0.4609 - val_accuracy: 0.8268\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9817\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91129, saving model to tuner_run/ensemble/weights/b0_ensemple_11_warm\\cp.cpkt\n",
      "283/283 [==============================] - 116s 384ms/step - loss: 0.0729 - accuracy: 0.9817 - val_loss: 0.2577 - val_accuracy: 0.9113\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9953\n",
      "Epoch 2: val_accuracy did not improve from 0.91129\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0281 - accuracy: 0.9953 - val_loss: 0.3930 - val_accuracy: 0.8693\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9964\n",
      "Epoch 3: val_accuracy improved from 0.91129 to 0.92063, saving model to tuner_run/ensemble/weights/b0_ensemple_11_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.2211 - val_accuracy: 0.9206\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.92063\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.3232 - val_accuracy: 0.9004\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9978\n",
      "Epoch 5: val_accuracy did not improve from 0.92063\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.2518 - val_accuracy: 0.9144\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9980\n",
      "Epoch 6: val_accuracy improved from 0.92063 to 0.92797, saving model to tuner_run/ensemble/weights/b0_ensemple_11_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2075 - val_accuracy: 0.9280\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9983\n",
      "Epoch 7: val_accuracy did not improve from 0.92797\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.2504 - val_accuracy: 0.9209\n",
      "11 [0.9112939238548279, 0.8692752122879028, 0.9206314086914062, 0.9004001617431641, 0.914406418800354, 0.9279679656028748, 0.9208537340164185]\n",
      "jo\n",
      "283/283 [==============================] - 105s 353ms/step - loss: 0.1463 - accuracy: 0.9573 - val_loss: 0.3687 - val_accuracy: 0.8517\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9823\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92374, saving model to tuner_run/ensemble/weights/b0_ensemple_12_warm\\cp.cpkt\n",
      "283/283 [==============================] - 116s 382ms/step - loss: 0.0691 - accuracy: 0.9823 - val_loss: 0.2210 - val_accuracy: 0.9237\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9949\n",
      "Epoch 2: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0272 - accuracy: 0.9949 - val_loss: 0.4084 - val_accuracy: 0.8619\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9961\n",
      "Epoch 3: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 0.4812 - val_accuracy: 0.8648\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9971\n",
      "Epoch 4: val_accuracy did not improve from 0.92374\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.3703 - val_accuracy: 0.8817\n",
      "Epoch 4: early stopping\n",
      "12 [0.9237439036369324, 0.8619386553764343, 0.8648288249969482, 0.8817251920700073]\n",
      "jo\n",
      "283/283 [==============================] - 106s 355ms/step - loss: 0.1508 - accuracy: 0.9546 - val_loss: 0.3947 - val_accuracy: 0.8375\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9786\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91974, saving model to tuner_run/ensemble/weights/b0_ensemple_13_warm\\cp.cpkt\n",
      "283/283 [==============================] - 116s 384ms/step - loss: 0.0803 - accuracy: 0.9786 - val_loss: 0.2300 - val_accuracy: 0.9197\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9949\n",
      "Epoch 2: val_accuracy did not improve from 0.91974\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0291 - accuracy: 0.9949 - val_loss: 0.3214 - val_accuracy: 0.8893\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9964\n",
      "Epoch 3: val_accuracy did not improve from 0.91974\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0213 - accuracy: 0.9964 - val_loss: 0.2294 - val_accuracy: 0.9195\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.91974\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.3061 - val_accuracy: 0.8966\n",
      "Epoch 4: early stopping\n",
      "13 [0.9197421073913574, 0.8892841339111328, 0.9195197820663452, 0.8966206908226013]\n",
      "jo\n",
      "283/283 [==============================] - 106s 355ms/step - loss: 0.1487 - accuracy: 0.9564 - val_loss: 0.3909 - val_accuracy: 0.8562\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9818\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92930, saving model to tuner_run/ensemble/weights/b0_ensemple_14_warm\\cp.cpkt\n",
      "283/283 [==============================] - 116s 382ms/step - loss: 0.0696 - accuracy: 0.9818 - val_loss: 0.2015 - val_accuracy: 0.9293\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9952\n",
      "Epoch 2: val_accuracy did not improve from 0.92930\n",
      "283/283 [==============================] - 106s 374ms/step - loss: 0.0272 - accuracy: 0.9952 - val_loss: 0.2652 - val_accuracy: 0.9084\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9962\n",
      "Epoch 3: val_accuracy did not improve from 0.92930\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0207 - accuracy: 0.9962 - val_loss: 0.4296 - val_accuracy: 0.8762\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.92930\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 0.2608 - val_accuracy: 0.9211\n",
      "Epoch 4: early stopping\n",
      "14 [0.929301917552948, 0.908403754234314, 0.8761671781539917, 0.9210760593414307]\n",
      "jo\n",
      "283/283 [==============================] - 105s 353ms/step - loss: 0.1427 - accuracy: 0.9580 - val_loss: 0.3671 - val_accuracy: 0.8519\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9851\n",
      "Epoch 1: val_accuracy improved from -inf to 0.90929, saving model to tuner_run/ensemble/weights/b0_ensemple_15_warm\\cp.cpkt\n",
      "283/283 [==============================] - 116s 383ms/step - loss: 0.0631 - accuracy: 0.9851 - val_loss: 0.2620 - val_accuracy: 0.9093\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9952\n",
      "Epoch 2: val_accuracy did not improve from 0.90929\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0265 - accuracy: 0.9952 - val_loss: 0.3577 - val_accuracy: 0.8831\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9969\n",
      "Epoch 3: val_accuracy improved from 0.90929 to 0.92597, saving model to tuner_run/ensemble/weights/b0_ensemple_15_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.2143 - val_accuracy: 0.9260\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9970\n",
      "Epoch 4: val_accuracy did not improve from 0.92597\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.2243 - val_accuracy: 0.9222\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9980\n",
      "Epoch 5: val_accuracy did not improve from 0.92597\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0137 - accuracy: 0.9980 - val_loss: 0.2629 - val_accuracy: 0.9213\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9980\n",
      "Epoch 6: val_accuracy improved from 0.92597 to 0.92752, saving model to tuner_run/ensemble/weights/b0_ensemple_15_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2391 - val_accuracy: 0.9275\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9978\n",
      "Epoch 7: val_accuracy did not improve from 0.92752\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.2198 - val_accuracy: 0.9233\n",
      "15 [0.909292995929718, 0.8830591440200806, 0.9259670972824097, 0.9221876263618469, 0.9212983250617981, 0.9275233149528503, 0.923299252986908]\n",
      "jo\n",
      "283/283 [==============================] - 105s 354ms/step - loss: 0.1399 - accuracy: 0.9595 - val_loss: 0.3593 - val_accuracy: 0.8655\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9831\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94131, saving model to tuner_run/ensemble/weights/b0_ensemple_16_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 384ms/step - loss: 0.0690 - accuracy: 0.9831 - val_loss: 0.1721 - val_accuracy: 0.9413\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9946\n",
      "Epoch 2: val_accuracy did not improve from 0.94131\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0286 - accuracy: 0.9946 - val_loss: 0.4141 - val_accuracy: 0.8695\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9961\n",
      "Epoch 3: val_accuracy did not improve from 0.94131\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0211 - accuracy: 0.9961 - val_loss: 0.3449 - val_accuracy: 0.8868\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9971\n",
      "Epoch 4: val_accuracy did not improve from 0.94131\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0164 - accuracy: 0.9971 - val_loss: 0.2417 - val_accuracy: 0.9104\n",
      "Epoch 4: early stopping\n",
      "16 [0.9413072466850281, 0.869497537612915, 0.8868386149406433, 0.910404622554779]\n",
      "jo\n",
      "283/283 [==============================] - 105s 354ms/step - loss: 0.1411 - accuracy: 0.9578 - val_loss: 0.4727 - val_accuracy: 0.8195\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9815\n",
      "Epoch 1: val_accuracy improved from -inf to 0.90863, saving model to tuner_run/ensemble/weights/b0_ensemple_17_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 383ms/step - loss: 0.0746 - accuracy: 0.9815 - val_loss: 0.2622 - val_accuracy: 0.9086\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9946\n",
      "Epoch 2: val_accuracy did not improve from 0.90863\n",
      "283/283 [==============================] - 106s 375ms/step - loss: 0.0292 - accuracy: 0.9946 - val_loss: 0.2856 - val_accuracy: 0.9031\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 3: val_accuracy did not improve from 0.90863\n",
      "283/283 [==============================] - 107s 376ms/step - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.2764 - val_accuracy: 0.8993\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9976\n",
      "Epoch 4: val_accuracy improved from 0.90863 to 0.92063, saving model to tuner_run/ensemble/weights/b0_ensemple_17_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.2578 - val_accuracy: 0.9206\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9975\n",
      "Epoch 5: val_accuracy did not improve from 0.92063\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 0.3509 - val_accuracy: 0.9051\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9978\n",
      "Epoch 6: val_accuracy improved from 0.92063 to 0.93775, saving model to tuner_run/ensemble/weights/b0_ensemple_17_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.2066 - val_accuracy: 0.9378\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9983\n",
      "Epoch 7: val_accuracy did not improve from 0.93775\n",
      "283/283 [==============================] - 106s 376ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.2145 - val_accuracy: 0.9342\n",
      "17 [0.9086260795593262, 0.9030680060386658, 0.8992885947227478, 0.9206314086914062, 0.9050689339637756, 0.9377501010894775, 0.934192955493927]\n",
      "jo\n",
      "283/283 [==============================] - 106s 354ms/step - loss: 0.1419 - accuracy: 0.9586 - val_loss: 0.4003 - val_accuracy: 0.8442\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9855\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86683, saving model to tuner_run/ensemble/weights/b0_ensemple_18_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 384ms/step - loss: 0.0601 - accuracy: 0.9855 - val_loss: 0.3899 - val_accuracy: 0.8668\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9948\n",
      "Epoch 2: val_accuracy improved from 0.86683 to 0.92197, saving model to tuner_run/ensemble/weights/b0_ensemple_18_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0266 - accuracy: 0.9948 - val_loss: 0.2230 - val_accuracy: 0.9220\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9971\n",
      "Epoch 3: val_accuracy did not improve from 0.92197\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.2881 - val_accuracy: 0.9031\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9972\n",
      "Epoch 4: val_accuracy did not improve from 0.92197\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.3515 - val_accuracy: 0.8966\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9973\n",
      "Epoch 5: val_accuracy improved from 0.92197 to 0.93486, saving model to tuner_run/ensemble/weights/b0_ensemple_18_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.1944 - val_accuracy: 0.9349\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9983\n",
      "Epoch 6: val_accuracy did not improve from 0.93486\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.3417 - val_accuracy: 0.9051\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 7: val_accuracy did not improve from 0.93486\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.2127 - val_accuracy: 0.9257\n",
      "18 [0.8668296933174133, 0.9219653010368347, 0.9030680060386658, 0.8966206908226013, 0.9348599314689636, 0.9050689339637756, 0.9257447719573975]\n",
      "jo\n",
      "283/283 [==============================] - 105s 353ms/step - loss: 0.1421 - accuracy: 0.9590 - val_loss: 0.4182 - val_accuracy: 0.8355\n",
      "was\n",
      "Epoch 1/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9816\n",
      "Epoch 1: val_accuracy improved from -inf to 0.90907, saving model to tuner_run/ensemble/weights/b0_ensemple_19_warm\\cp.cpkt\n",
      "283/283 [==============================] - 115s 385ms/step - loss: 0.0747 - accuracy: 0.9816 - val_loss: 0.2771 - val_accuracy: 0.9091\n",
      "Epoch 2/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9941\n",
      "Epoch 2: val_accuracy improved from 0.90907 to 0.93219, saving model to tuner_run/ensemble/weights/b0_ensemple_19_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0304 - accuracy: 0.9941 - val_loss: 0.1918 - val_accuracy: 0.9322\n",
      "Epoch 3/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9966\n",
      "Epoch 3: val_accuracy did not improve from 0.93219\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0201 - accuracy: 0.9966 - val_loss: 0.3717 - val_accuracy: 0.8842\n",
      "Epoch 4/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9973\n",
      "Epoch 4: val_accuracy did not improve from 0.93219\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: 0.4186 - val_accuracy: 0.8688\n",
      "Epoch 5/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9978\n",
      "Epoch 5: val_accuracy improved from 0.93219 to 0.93241, saving model to tuner_run/ensemble/weights/b0_ensemple_19_warm\\cp.cpkt\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0142 - accuracy: 0.9978 - val_loss: 0.2058 - val_accuracy: 0.9324\n",
      "Epoch 6/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9978\n",
      "Epoch 6: val_accuracy did not improve from 0.93241\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.3069 - val_accuracy: 0.9033\n",
      "Epoch 7/7\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9982\n",
      "Epoch 7: val_accuracy did not improve from 0.93241\n",
      "283/283 [==============================] - 107s 377ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2607 - val_accuracy: 0.9289\n",
      "19 [0.9090706706047058, 0.9321920871734619, 0.8841707706451416, 0.8688305616378784, 0.9324144124984741, 0.903290331363678, 0.9288572669029236]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    name = f\"b0_ensemple_{i}\"\n",
    "    cnn = build_cnn()\n",
    "\n",
    "    model = build_model(pars,cnn)\n",
    "\n",
    "    model\n",
    "    print(\"jo\")\n",
    "    model.fit(train_ds, epochs=1, validation_data=val_ds)\n",
    "\n",
    "    print(\"was\")\n",
    "    save_dir = f\"tuner_run/ensemble/weights/{name}_cold/\"\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    model.save_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "\n",
    "    cnn = warm_model(cnn)\n",
    "    model = build_model(pars,cnn)\n",
    "    model.load_weights(save_dir + \"cp.cpkt\")\n",
    "\n",
    "    callbacks = get_callbacks(name)\n",
    "    hist = model.fit(train_ds, epochs=7, validation_data=val_ds,callbacks=callbacks)\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    max_acc = max(val_acc)\n",
    "\n",
    "    perfomances[i] = val_acc\n",
    "\n",
    "    print(i,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfomances = {i: max(perfomances[i]) for i in perfomances }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuner_run/ensemble_results.json\",'w') as f:\n",
    "\n",
    "    json.dump(perfomances,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  2,  1, 16, 17], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = np.array(list(perfomances.values()))\n",
    "np.argsort(-val)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94886619, 0.94219655, 0.9417519 , 0.94130725, 0.9377501 ,\n",
       "       0.93641621, 0.93574923, 0.93485993, 0.93463761, 0.93241441,\n",
       "       0.93108046, 0.92930192, 0.92796797, 0.92752331, 0.9237439 ,\n",
       "       0.9237439 , 0.9228546 , 0.92240995, 0.92152065, 0.91974211])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[awaitnp.argsort(-val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 88s 318ms/step - loss: 0.1913 - accuracy: 0.9515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19134901463985443, 0.9515340328216553]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(i):\n",
    "    cnn = build_cnn()\n",
    "\n",
    "    model = build_model(pars,cnn)\n",
    "    name = f\"b0_ensemple_{i}\"\n",
    "    model.load_weights(f\"tuner_run/ensemble/weights/{name}_warm/cp.cpkt\")\n",
    "    return model\n",
    "\n",
    "_ , val_ds = seq_generator.get_train_and_val(batch_size=20)\n",
    "val_ds = val_ds.map(lambda x,y: (x,tf.one_hot(y,2)))\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input([5,260,260,3])\n",
    "x = [load_model(i)(inputs) for i in [ 4,  2,  1, 16, 17]]\n",
    "\n",
    "outputs = tf.math.reduce_mean(x,axis = 0)\n",
    "\n",
    "ensemble = tf.keras.Model(inputs,outputs)\n",
    "ensemble.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "ensemble.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "225/225 [==============================] - 54s 194ms/step - loss: 0.1977 - accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19770410656929016, 0.9517563581466675]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input([5,260,260,3])\n",
    "x = [load_model(i)(inputs) for i in [ 4,  2,  1]]\n",
    "\n",
    "outputs = tf.math.reduce_mean(x,axis = 0)\n",
    "\n",
    "ensemble = tf.keras.Model(inputs,outputs)\n",
    "ensemble.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "ensemble.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 17s 66ms/step\n",
      "225/225 [==============================] - 17s 66ms/step\n",
      "225/225 [==============================] - 17s 66ms/step\n",
      "225/225 [==============================] - 17s 67ms/step\n",
      "225/225 [==============================] - 17s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "val_df = pd.read_feather('new_train_seqs.df').set_index('index').query('ds_type == \"val\"')\n",
    "val_df['labels'] = (val_df.view_direction == 'Sideways').astype(float)\n",
    "\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "def get_errors(i):\n",
    "    tf.keras.backend.clear_session()\n",
    "    df = val_df.copy()\n",
    "    model = load_model(i)\n",
    "    preds = model.predict(val_ds,verbose= 1)[:,1]\n",
    "    df['loss'] = bce(df.labels.values[:,None],preds[:,None])\n",
    "\n",
    "    return df[(0.5 < df.loss)].index, df[(0.5 < preds) != df.labels].index \n",
    "\n",
    "errors = [get_errors(i) for i in [ 4,  2,  1, 16, 17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_loss  = np.concatenate([i[0] for i in errors])\n",
    "fp  = np.concatenate([i[1] for i in errors])\n",
    "inds,cs = np.unique(low_loss,return_counts=1)\n",
    "fp,fcs = np.unique(low_loss,return_counts=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 345/345 [00:47<00:00,  7.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm, matplotlib.pyplot as plt\n",
    "\n",
    "# val_df = pd.read_feather('imgl.df').set_index('index')\n",
    "func = lambda s: s[s.find(\"images/\")+7:]\n",
    "val_df[\"local_path\"] = np.array([[f\"../seq_data/{s}/{func(i)}\"for i in c] for c,s in zip(val_df.Paths,val_df.ds_type)]).tolist()\n",
    "high_loss = val_df.loc[inds[cs> 1]]\n",
    "\n",
    "p = \"tmp/ensemble_errors/\"\n",
    "os.makedirs(p,exist_ok=True)\n",
    "\n",
    "for n in tqdm.tqdm(range(len(high_loss))):\n",
    "\n",
    "\n",
    "\n",
    "    row = high_loss.iloc[n]\n",
    "    fig, ax = plt.subplots(2,2,figsize=(12,12))\n",
    "    keys = row['local_path']\n",
    "    #np.random.shuffle(keys)\n",
    "    for i,a in enumerate(ax.flatten()):\n",
    "        try:\n",
    "            a.imshow(plt.imread(keys[i]))\n",
    "        except: pass\n",
    "        a.axis('off')\n",
    "\n",
    "    label = row['view_direction']\n",
    "    if high_loss.index[n] in fp:\n",
    "    \n",
    "        pre = fcs[fp ==high_loss.index[n]] \n",
    "\n",
    "    else:\n",
    "\n",
    "        pre = 0\n",
    "\n",
    "    text = f\"Label: {row['view_direction']}, N False Pred: {pre[0]}, N High Loss: {cs[inds ==high_loss.index[n]][0]}\"\n",
    "\n",
    "    plt.suptitle(text)\n",
    "    path = p +  str(high_loss.index[n]) + \".jpg\"\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('cleaned_seqs.df').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00027476179924662087"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front = [int(i[:-4]) for i in os.listdir('tmp/front')]\n",
    "side = [int(i[:-4]) for i in os.listdir('tmp/side')]\n",
    "\n",
    "change =( df.loc[front, \"view_direction\"] != \"Forward\").sum() + ( df.loc[side, \"view_direction\"] != \"Sideways\").sum()\n",
    "change/len(df)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[front, \"view_direction\"] = \"Forward\"\n",
    "df.loc[side, \"view_direction\"] = \"Sideways\"\n",
    "\n",
    "df.reset_index().to_feather('cleaned_seqs.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for i in range(20):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a = model.evaluate(val_ds.take(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('felix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64aad402826e5067045a3f2545cdf45209700db649eac24e1eb71cad2d7c755c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
