{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook I had a look at the sequence with a particulary high loss on the single view_direction image model. By this I could detect a some false labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 11:03:28.766867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-23 11:03:28.766912: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/felix/anaconda3/envs/r/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Here I just loaded the training images and inserted some addiational info to the df\n",
    "\n",
    "# df = pd.read_feather(\"traning_imgs.df\")\n",
    "# old = pd.read_feather(\"../data_analysis/prelim.feather\").set_index(\"key\")\n",
    "# df[\"seq_key\"] = old.loc[df[\"key\"].values,\"sequence_key\"].values\n",
    "# df[\"view_direction\"] = old.loc[df[\"key\"].values,\"view_direction\"].values\n",
    "# df[\"city\"] = df.path.apply(lambda x: x[22: x.find(\"/\",22)])\n",
    "# func = lambda s: s[s.find(\"images/\")+7:]\n",
    "# df[\"local_path\"] =  \"../seq_data/\" + df.ds_type + \"/\" + df.path.apply(func).values\n",
    "# df = df.sort_values([\"city\",\"seq_key\",\"og_cluster\"])\n",
    "# df.index = range(len(df))\n",
    "# df.to_feather(\"traning_imgs.df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was for calculating the losses and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------- Get Predictions -----------\n",
    "\n",
    "# df = pd.read_feather(\"traning_imgs.df\")\n",
    "\n",
    "# model = tf.keras.models.load_model(\"../../view_directions_task_single_image/Training/training_results/last_model/ENB0_All/model\")\n",
    "# def mapping(path,label):\n",
    "\n",
    "#     image = tf.io.read_file(path)\n",
    "#     image = tf.io.decode_jpeg(image, channels=3)\n",
    "#     label = tf.one_hot(label,2)\n",
    "#     return image, label\n",
    "# ds = tf.data.Dataset.from_tensor_slices((df.local_path.values,(df.view_direction==\"Sideways\").apply(int).values)).map(mapping).batch(64)\n",
    "\n",
    "# preds = model.predict(ds,verbose=1) # predict \n",
    "\n",
    "# # ----------- Save them to the df -----------\n",
    "\n",
    "# df[\"lon\"] = preds[:,0]\n",
    "# df[\"lat\"] = preds[:,1]\n",
    "# df.to_feather('imgs_preds.df')\n",
    "\n",
    "# df = pd.read_feather('imgs_preds.df').sort_values([\"city\",'seq_key','og_cluster'])\n",
    "# labels = tf.one_hot((df.view_direction == \"Sideways\").apply(int).values,2).numpy()\n",
    "# preds = np.array([df.lon,df.lat]).T\n",
    "\n",
    "# df['label0'] = labels[:,0]\n",
    "# df['label1'] = labels[:,1]\n",
    "\n",
    "# # ----------- Calculate loss by cluster -----------\n",
    "\n",
    "\n",
    "# index = []\n",
    "# vals = []\n",
    "# bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "# for i in tqdm.tqdm(df.groupby([\"city\",'seq_key','og_cluster'])):\n",
    "\n",
    "#     preds = np.array([i[1].lon.values, i[1].lat.values]).T\n",
    "#     labels = np.array([i[1].label0.values, i[1].label1.values]).T\n",
    "    \n",
    "#     loss = bce(labels,preds).numpy()\n",
    "#     vals.append(loss)\n",
    "#     index.append(i[0])\n",
    "\n",
    "# # ----------- Save values -----------\n",
    "\n",
    "\n",
    "# losses = pd.DataFrame(vals,index=pd.MultiIndex.from_tuples(index),columns=['loss'])\n",
    "# losses.sort_values(\"loss\",ascending=False,inplace=True)\n",
    "# losses.reset_index().to_feather('losses.df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>local_path</th>\n",
       "      <th>view_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>seq_key</th>\n",
       "      <th>og_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">moscow</th>\n",
       "      <th>88f4LVGNDL4iRFqim7cxag</th>\n",
       "      <th>1690</th>\n",
       "      <td>15.379092</td>\n",
       "      <td>[../seq_data/test/vA89Ip9RxWNHA28ZUHgPlA.jpg, ...</td>\n",
       "      <td>Sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8YtHW9q4gIQLorhQdIfZTQ</th>\n",
       "      <th>3015</th>\n",
       "      <td>15.058754</td>\n",
       "      <td>[../seq_data/test/4oBMNU3mQGNI0xN-rAkOQw.jpg, ...</td>\n",
       "      <td>Sideways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <th>xsqtzd8zs5kp51plyijhxm</th>\n",
       "      <th>11</th>\n",
       "      <td>14.708673</td>\n",
       "      <td>[../seq_data/train/Proo9t0uBay02aQaytJ_9A.jpg,...</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               loss  \\\n",
       "city   seq_key                og_cluster              \n",
       "moscow 88f4LVGNDL4iRFqim7cxag 1690        15.379092   \n",
       "       8YtHW9q4gIQLorhQdIfZTQ 3015        15.058754   \n",
       "paris  xsqtzd8zs5kp51plyijhxm 11          14.708673   \n",
       "\n",
       "                                                                                 local_path  \\\n",
       "city   seq_key                og_cluster                                                      \n",
       "moscow 88f4LVGNDL4iRFqim7cxag 1690        [../seq_data/test/vA89Ip9RxWNHA28ZUHgPlA.jpg, ...   \n",
       "       8YtHW9q4gIQLorhQdIfZTQ 3015        [../seq_data/test/4oBMNU3mQGNI0xN-rAkOQw.jpg, ...   \n",
       "paris  xsqtzd8zs5kp51plyijhxm 11          [../seq_data/train/Proo9t0uBay02aQaytJ_9A.jpg,...   \n",
       "\n",
       "                                         view_direction  \n",
       "city   seq_key                og_cluster                 \n",
       "moscow 88f4LVGNDL4iRFqim7cxag 1690             Sideways  \n",
       "       8YtHW9q4gIQLorhQdIfZTQ 3015             Sideways  \n",
       "paris  xsqtzd8zs5kp51plyijhxm 11                Forward  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = pd.read_feather(\"losses.df\").set_index([\"level_0\",\"level_1\",\"level_2\"])\n",
    "df = pd.read_feather('imgs_preds.df').sort_values([\"city\",'seq_key','og_cluster'])\n",
    "losses.index.names = ['city', 'seq_key', 'og_cluster']\n",
    "paths = df.groupby([\"city\",'seq_key','og_cluster'])[\"local_path\"].unique()\n",
    "view = df.groupby([\"city\",'seq_key','og_cluster'])[\"view_direction\"].min()\n",
    "losses = losses.join(paths).join(view)\n",
    "losses.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cluster with average loss over 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2 < losses.loss) ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Images of Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_loss = losses[(2 < losses.loss) ]\n",
    "# for n in tqdm.tqdm(range(len(high_loss))):\n",
    "\n",
    "#     row = high_loss.iloc[n]\n",
    "#     fig, ax = plt.subplots(4,4,figsize=(12,12))\n",
    "#     keys = row['local_path']\n",
    "#     #np.random.shuffle(keys)\n",
    "#     for i,a in enumerate(ax.flatten()):\n",
    "#         try:\n",
    "#             a.imshow(plt.imread(keys[i]))\n",
    "#         except: pass\n",
    "#         a.axis('off')\n",
    "#     plt.suptitle(f\"{row['view_direction']} {row['loss'] :.2f}\")\n",
    "#     path = \"hl/\" + \"|\".join([str(u) for u in high_loss.index[n]]) + \".jpg\"\n",
    "#     plt.savefig(path)\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_row(row):\n",
    "    fig, ax = plt.subplots(4,3,figsize=(8,8))\n",
    "    keys = row['local_path']\n",
    "    np.random.shuffle(keys)\n",
    "    for i,a in enumerate(ax.flatten()):\n",
    "        try:\n",
    "            a.imshow(plt.imread(keys[i]))\n",
    "        except:\n",
    "            pass\n",
    "        a.axis('off')\n",
    "    plt.suptitle(f\"{row['view_direction']} {row['loss'] :.2f}\")\n",
    "    plt.show()\n",
    "\n",
    "def reindex(x):\n",
    "    x = x[:-4].split(\"|\")\n",
    "    x[2] = int(x[2])\n",
    "    return tuple(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relabel the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of indices\n",
    "\n",
    "relabel_to_forward = [reindex(seq) for seq in os.listdir(\"lon\") if losses.loc[reindex(seq),\"view_direction\"] == \"Sideways\"]\n",
    "relabel_to_side = [reindex(seq) for seq in os.listdir(\"side\") if losses.loc[reindex(seq),\"view_direction\"] != \"Sideways\"]\n",
    "to_trop = [reindex(i) for i in os.listdir(\"del\")]\n",
    "\n",
    "\n",
    "def get_indices_fast(props):\n",
    "\n",
    "    agg = []\n",
    "    for i in relabel_to_forward:\n",
    "\n",
    "        k = df.copy()\n",
    "        k = k.loc[k.city==i[0]]\n",
    "        k = k.loc[k.seq_key ==i[1]]\n",
    "        k = k.loc[k.og_cluster == i[2]]\n",
    "        agg.append(k.index.values)\n",
    "    \n",
    "    return np.concatenate(agg)\n",
    "\n",
    "# -------------- Relabel images --------------\n",
    "to_front = get_indices_fast(relabel_to_forward)\n",
    "to_side = get_indices_fast(relabel_to_side)\n",
    "df.loc[to_front,\"view_direction\"] = \"Forward\"\n",
    "df.loc[to_side,\"view_direction\"] = \"Sideways\"\n",
    "\n",
    "# -------------- Relabel Seqs  --------------\n",
    "\n",
    "df = df.set_index(\"key\")\n",
    "seqs_df = pd.read_feather(\"training.df\").set_index(\"index\")\n",
    "seqs_df[\"view_direction\"] = seqs_df[\"keys\"].apply(lambda x: df.loc[x[0],\"view_direction\"])\n",
    "\n",
    "# -------------- Drop bad seqs --------------\n",
    "\n",
    "to_del = get_indices_fast(to_trop)\n",
    "trash = seqs_df[\"keys\"].apply(lambda x: x[0] in to_del)\n",
    "seqs_df = seqs_df [ ~trash]\n",
    "df.drop(index = to_del,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cleaned seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_feather(\"cleaned_images.df\")\n",
    "seqs_df.reset_index().to_feather(\"cleaned_seqs.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('r')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b1fae9b4f84de5a0151293b92063dea66447e44ce8e797ae8cc1ec46d1c2819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
